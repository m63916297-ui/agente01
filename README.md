# Agente AutÃ³nomo de AnÃ¡lisis y SÃ­ntesis de DocumentaciÃ³n TÃ©cnica

## DescripciÃ³n del Proyecto

Este proyecto implementa un agente de IA autÃ³nomo capaz de procesar documentaciÃ³n tÃ©cnica desde URLs, entenderla y responder preguntas complejas sobre ella. El sistema utiliza LangGraph para orquestar el flujo de trabajo y expone su funcionalidad a travÃ©s de una API RESTful.

## Arquitectura de la SoluciÃ³n

### Componentes Principales

1. **API RESTful (FastAPI)**: Interfaz principal para interactuar con el agente
2. **LangGraph Workflow**: Orquesta el flujo de procesamiento y respuesta
3. **Base de Datos Vectorial (ChromaDB)**: Almacena embeddings de la documentaciÃ³n
4. **Base de Datos SQLite**: Persiste conversaciones y estados de procesamiento
5. **Web Scraping**: Extrae contenido de URLs de documentaciÃ³n
6. **RAG Pipeline**: RecuperaciÃ³n y generaciÃ³n aumentada de respuestas

### Diagrama de Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cliente       â”‚    â”‚   FastAPI       â”‚    â”‚   LangGraph     â”‚
â”‚   (Frontend)    â”‚â—„â”€â”€â–ºâ”‚   (API Layer)   â”‚â—„â”€â”€â–ºâ”‚   (Workflow)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                       â”‚
                                â–¼                       â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   SQLite DB     â”‚    â”‚   ChromaDB      â”‚
                       â”‚   (Chat History)â”‚    â”‚   (Embeddings)  â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de LangGraph

```
Input Node â†’ Intent Analysis â†’ Conditional Router
     â†“              â†“              â†“
Memory Node â† Response Gen â† RAG Node
     â†“              â†“              â†“
Code Format â† Output Node â† Context Builder
```

## Decisiones TÃ©cnicas

### Framework Backend: FastAPI
- **Rendimiento**: Alto rendimiento con async/await
- **DocumentaciÃ³n automÃ¡tica**: OpenAPI/Swagger integrado
- **ValidaciÃ³n**: Pydantic para validaciÃ³n de datos
- **Facilidad de desarrollo**: Sintaxis moderna y intuitiva

### Base de Datos: SQLite + ChromaDB
- **SQLite**: Para persistencia de conversaciones y estados
- **ChromaDB**: Base de datos vectorial para embeddings
- **Simplicidad**: No requiere configuraciÃ³n de servidor externo

### Modelos de IA
- **Embeddings**: sentence-transformers/all-MiniLM-L6-v2
- **LLM**: Ollama (llama3.2) para generaciÃ³n de respuestas
- **AnÃ¡lisis de intenciÃ³n**: Clasificador personalizado

## InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos

- Python 3.9+
- Ollama (para el modelo LLM)
- Git

### InstalaciÃ³n

1. **Clonar el repositorio**:
```bash
git clone <repository-url>
cd test-AI
```

2. **Crear entorno virtual**:
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o
venv\Scripts\activate     # Windows
```

3. **Instalar dependencias**:
```bash
pip install -r requirements.txt
```

4. **Configurar variables de entorno**:
```bash
cp .env.example .env
# Editar .env con tus configuraciones
```

5. **Inicializar base de datos**:
```bash
python scripts/init_db.py
```

6. **Ejecutar el servidor**:
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### Variables de Entorno

```env
# Base de datos
DATABASE_URL=sqlite:///./app.db

# ChromaDB
CHROMA_PERSIST_DIRECTORY=./chroma_db

# Ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# ConfiguraciÃ³n de la aplicaciÃ³n
MAX_TOKENS=4096
TEMPERATURE=0.7
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
```

## Uso de la API

### 1. Procesar DocumentaciÃ³n

```bash
curl -X POST "http://localhost:8000/api/v1/process-documentation" \
     -H "Content-Type: application/json" \
     -d '{
       "url": "https://docs.python.org/3/tutorial/",
       "chat_id": "chat_123"
     }'
```

### 2. Verificar Estado de Procesamiento

```bash
curl -X GET "http://localhost:8000/api/v1/processing-status/chat_123"
```

### 3. Hacer Preguntas

```bash
curl -X POST "http://localhost:8000/api/v1/chat/chat_123" \
     -H "Content-Type: application/json" \
     -d '{
       "message": "Â¿CÃ³mo funciona la herencia en Python?",
       "user_id": "user_456"
     }'
```

### 4. Obtener Historial

```bash
curl -X GET "http://localhost:8000/api/v1/chat-history/chat_123"
```

## Estructura del Proyecto

```
test-AI/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI app
â”‚   â”œâ”€â”€ config.py              # Configuraciones
â”‚   â”œâ”€â”€ database.py            # ConexiÃ³n a BD
â”‚   â”œâ”€â”€ models/                # Modelos Pydantic
â”‚   â”œâ”€â”€ api/                   # Endpoints de la API
â”‚   â”œâ”€â”€ services/              # LÃ³gica de negocio
â”‚   â”œâ”€â”€ agents/                # Agentes LangGraph
â”‚   â”œâ”€â”€ processors/            # Procesamiento de documentos
â”‚   â””â”€â”€ utils/                 # Utilidades
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ init_db.py            # InicializaciÃ³n de BD
â”œâ”€â”€ tests/                    # Tests unitarios
â”œâ”€â”€ requirements.txt          # Dependencias
â”œâ”€â”€ .env.example             # Variables de entorno
â””â”€â”€ README.md               # Este archivo
```

## CaracterÃ­sticas Implementadas

### âœ… Funcionalidades Completadas

1. **API RESTful completa** con todos los endpoints requeridos
2. **LangGraph workflow** con nodos especializados
3. **Web scraping** inteligente con limpieza de HTML
4. **SegmentaciÃ³n semÃ¡ntica** de documentos
5. **Sistema RAG** personalizado con embeddings
6. **AnÃ¡lisis de intenciÃ³n** del usuario
7. **Memoria de conversaciÃ³n** persistente
8. **Formateo de cÃ³digo** automÃ¡tico
9. **Procesamiento asÃ­ncrono** de documentos
10. **Base de datos vectorial** para bÃºsquedas semÃ¡nticas

### ğŸ”§ Componentes TÃ©cnicos

- **FastAPI**: Framework web moderno y rÃ¡pido
- **LangGraph**: OrquestaciÃ³n de flujos de IA
- **ChromaDB**: Base de datos vectorial
- **SQLite**: Persistencia de datos
- **BeautifulSoup**: Web scraping
- **Sentence Transformers**: GeneraciÃ³n de embeddings
- **Ollama**: Modelo de lenguaje local
- **Pydantic**: ValidaciÃ³n de datos
- **AsyncIO**: ProgramaciÃ³n asÃ­ncrona

## Ejemplos de Uso

### Procesamiento de DocumentaciÃ³n de Python

```python
import requests

# 1. Iniciar procesamiento
response = requests.post("http://localhost:8000/api/v1/process-documentation", json={
    "url": "https://docs.python.org/3/tutorial/",
    "chat_id": "python_docs_001"
})

# 2. Verificar estado
status = requests.get("http://localhost:8000/api/v1/processing-status/python_docs_001")

# 3. Hacer preguntas
question = requests.post("http://localhost:8000/api/v1/chat/python_docs_001", json={
    "message": "Â¿CÃ³mo se define una funciÃ³n en Python?",
    "user_id": "user_123"
})
```

### Preguntas de Seguimiento

El agente mantiene contexto de la conversaciÃ³n, permitiendo preguntas como:
- "Â¿Puedes darme un ejemplo de lo anterior?"
- "Â¿Y cÃ³mo se aplica esto en clases?"
- "Â¿CuÃ¡l es la diferencia con otros lenguajes?"

## ContribuciÃ³n

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.